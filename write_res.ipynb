{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model import model_official\n",
    "from MFEA_lib.model.utils import *\n",
    "from MFEA_lib.operators.Search import *\n",
    "from MFEA_lib.tasks.Benchmark.Funcs import WCCI22_benchmark\n",
    "from MFEA_lib.EA import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_res(res, path_out):\n",
    "    with open(path_out, 'w') as fi:\n",
    "        for i in res:\n",
    "            fi.write(str(int(i[0])) + \", \")\n",
    "            for j in range(1, len(i)-1):\n",
    "                fi.write(str(i[j])+\", \")\n",
    "            fi.write(str(i[len(i)-1])+\"\\n\")\n",
    "\n",
    "def save_res(len_output, task, model_saved_loc, res_loc):\n",
    "    for id in range(1, 11):\n",
    "        model_saved = loadModel(model_saved_loc + f\"{id}.mso\", ls_tasks=task(id))\n",
    "        res = np.array(model_saved.ls_model[0].history_cost[:len_output])\n",
    "       \n",
    "        for i in range(1,model_saved.nb_run):\n",
    "            res = np.concatenate((res, np.array(model_saved.ls_model[i].history_cost[:len_output])), 1)\n",
    "        while res.shape[0] < len_output:\n",
    "            res = np.concatenate((res, res[-1].reshape(1,-1)), 0)\n",
    "        num_evals = (np.arange(1, len_output + 1) * 1000 * len(model_saved.tasks[0])).reshape(-1,1)\n",
    "        out = np.concatenate((num_evals, res), 1)\n",
    "        write_res(out, res_loc + f\"{id}.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save result of the complex benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_res(\n",
    "    len_output=100,\n",
    "    task=WCCI22_benchmark.get_complex_benchmark,\n",
    "    model_saved_loc=\"model_saved\\__static__\\WCCI22_complex\\model_benchmark_id_\",\n",
    "    res_loc=\"./result/MTO-complex/MTOSOO_P\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Save result of the many task benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_saved\\\\__static__\\\\WCCI22_many\\\\model_benchmark_id_2.mso'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Vincent\\Documents\\Lab\\Competition\\official\\MFEA_MSO\\write_res.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39m# Save result of the many task benchmark\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=2'>3</a>\u001b[0m save_res(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=3'>4</a>\u001b[0m     len_output\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=4'>5</a>\u001b[0m     task\u001b[39m=\u001b[39;49mWCCI22_benchmark\u001b[39m.\u001b[39;49mget_50tasks_benchmark,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=5'>6</a>\u001b[0m     model_saved_loc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel_saved\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m__static__\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mWCCI22_many\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmodel_benchmark_id_\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=6'>7</a>\u001b[0m     res_loc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./result/MTO-many/MTOMSO_P\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000006?line=7'>8</a>\u001b[0m )\n",
      "\u001b[1;32md:\\Vincent\\Documents\\Lab\\Competition\\official\\MFEA_MSO\\write_res.ipynb Cell 2'\u001b[0m in \u001b[0;36msave_res\u001b[1;34m(len_output, task, model_saved_loc, res_loc)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_res\u001b[39m(len_output, task, model_saved_loc, res_loc):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000002?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000002?line=10'>11</a>\u001b[0m         model_saved \u001b[39m=\u001b[39m loadModel(model_saved_loc \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mid\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.mso\u001b[39;49m\u001b[39m\"\u001b[39;49m, ls_tasks\u001b[39m=\u001b[39;49mtask(\u001b[39mid\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000002?line=11'>12</a>\u001b[0m         res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(model_saved\u001b[39m.\u001b[39mls_model[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhistory_cost[:len_output])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Vincent/Documents/Lab/Competition/official/MFEA_MSO/write_res.ipynb#ch0000002?line=13'>14</a>\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,model_saved\u001b[39m.\u001b[39mnb_run):\n",
      "File \u001b[1;32md:\\Vincent\\Documents\\Lab\\Competition\\official\\MFEA_MSO\\MFEA_lib\\model\\utils.py:319\u001b[0m, in \u001b[0;36mloadModel\u001b[1;34m(PATH, ls_tasks, set_attribute)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39massert\u001b[39;00m path_tmp\u001b[39m.\u001b[39mname[i:] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mso\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOnly load model with .mso, not \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[0;32m    317\u001b[0m         path_tmp\u001b[39m.\u001b[39mname[i:]\n\u001b[1;32m--> 319\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(PATH, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    320\u001b[0m model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m    321\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_saved\\\\__static__\\\\WCCI22_many\\\\model_benchmark_id_2.mso'"
     ]
    }
   ],
   "source": [
    "# Save result of the many task benchmark\n",
    "\n",
    "save_res(\n",
    "    len_output=1000,\n",
    "    task=WCCI22_benchmark.get_50tasks_benchmark,\n",
    "    model_saved_loc=\"model_saved\\__static__\\WCCI22_many\\model_benchmark_id_\",\n",
    "    res_loc=\"./result/MTO-many/MTOMSO_P\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('learnCS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2d74ce3e99bc2d991502eaa9ff6878b69f13ebfe616751bd67e96721470575f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
