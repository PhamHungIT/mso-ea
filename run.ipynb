{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function ExecutionEngine._raw_object_cache_notify at 0x00000168444809D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\python\\lib\\site-packages\\llvmlite\\binding\\executionengine.py\", line 171, in _raw_object_cache_notify\n",
      "    def _raw_object_cache_notify(self, data):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from MFEA_lib.model import Model_Offical,Model_Test\n",
    "from MFEA_lib.model.utils import *\n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "from MFEA_lib.operators.Search import *\n",
    "from MFEA_lib.tasks.Benchmark.Funcs import WCCI22_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualDE(Individual):\n",
    "    def __init__(self, genes, dim= None) -> None:\n",
    "        super().__init__(genes, dim)\n",
    "        if genes is None:\n",
    "            self.genes: np.ndarray = np.random.rand(dim)\n",
    "        self.transfer =False\n",
    "        self.d_rank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = []\n",
    "ls_IndClass = []\n",
    "for i in range(1, 11, 1):\n",
    "    t, ic = WCCI22_benchmark.get_50tasks_benchmark(i)\n",
    "    ls_benchmark.append(t)\n",
    "    ls_IndClass.append(IndividualDE)\n",
    "\n",
    "name_benchmark = np.arange(len(ls_benchmark)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 00m 21.23s    5 % [=>                  ]  Pop_size: 1.92E+02  ,  Cost: 6.01E+02  6.01E+02  ,   Checking...Checking..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lab\\mso-ea\\MFEA_lib\\model\\utils.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.array(result)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'model' object has no attribute 'last_pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\utils.py:185\u001b[0m, in \u001b[0;36mMultiTimeModel.run\u001b[1;34m(self, nb_run, save_path, seed_arr, random_seed, replace_folder)\u001b[0m\n\u001b[0;32m    184\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_kwargs)\n\u001b[1;32m--> 185\u001b[0m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtime_end \u001b[39m-\u001b[39m model\u001b[39m.\u001b[39mtime_begin\n",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\Model_Test.py:390\u001b[0m, in \u001b[0;36mmodel.fit\u001b[1;34m(self, nb_inds_each_task, nb_generations, nb_inds_min, evaluate_initial_skillFactor, LSA, *args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m MUTATION_RATE :\n\u001b[1;32m--> 390\u001b[0m     offsprings\u001b[39m.\u001b[39m__addIndividual__(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpbest_1(population[t], t, indiv))\n\u001b[0;32m    391\u001b[0m \u001b[39melse\u001b[39;00m :\n",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\Model_Test.py:132\u001b[0m, in \u001b[0;36mmodel.pbest_1\u001b[1;34m(self, sub_pop, id_task, curr_indiv)\u001b[0m\n\u001b[0;32m    131\u001b[0m j_rand \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mlen\u001b[39m(curr_indiv))\n\u001b[1;32m--> 132\u001b[0m temp_genes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrand(\u001b[39mlen\u001b[39;49m(curr_indiv))\n\u001b[0;32m    133\u001b[0m inv \u001b[39m=\u001b[39m [curr_indiv,r1,r2]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Lab\\mso-ea\\run.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=7'>8</a>\u001b[0m     crossover\u001b[39m=\u001b[39m SBX_Crossover(nc \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=8'>9</a>\u001b[0m     mutation \u001b[39m=\u001b[39m Polynomial_Mutation(nm \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=9'>10</a>\u001b[0m     selection\u001b[39m=\u001b[39m ElitismSelection(random_percent\u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=12'>13</a>\u001b[0m     nb_inds_each_task\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=13'>14</a>\u001b[0m     nb_inds_min\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=16'>17</a>\u001b[0m     evaluate_initial_skillFactor\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=17'>18</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=18'>19</a>\u001b[0m a \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=19'>20</a>\u001b[0m     nb_run\u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=20'>21</a>\u001b[0m     save_path\u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m./model_saved/__static__/WCCI22_complex/model_official/model_benchmark_id_\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Lab/mso-ea/run.ipynb#ch0000003?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\utils.py:999\u001b[0m, in \u001b[0;36mMultiBenchmark.run\u001b[1;34m(self, nb_run, save_path)\u001b[0m\n\u001b[0;32m    997\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_kwargs) \n\u001b[0;32m    998\u001b[0m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_kwargs) \n\u001b[1;32m--> 999\u001b[0m model\u001b[39m.\u001b[39;49mrun(nb_run \u001b[39m=\u001b[39;49m nb_run, save_path\u001b[39m=\u001b[39;49m save_path \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mls_name_benchmark[idx]) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.mso\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[0;32m   1000\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mls_model\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\utils.py:193\u001b[0m, in \u001b[0;36mMultiTimeModel.run\u001b[1;34m(self, nb_run, save_path, seed_arr, random_seed, replace_folder)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRunning\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_attribute()\n\u001b[1;32m--> 193\u001b[0m save_result \u001b[39m=\u001b[39m saveModel(\u001b[39mself\u001b[39;49m, save_path)\n\u001b[0;32m    194\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mKeyboardInterrupt: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m    195\u001b[0m       save_result \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m model, model is not Done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    196\u001b[0m traceback\u001b[39m.\u001b[39mprint_exc()\n",
      "File \u001b[1;32md:\\Lab\\mso-ea\\MFEA_lib\\model\\utils.py:235\u001b[0m, in \u001b[0;36msaveModel\u001b[1;34m(model, PATH, remove_tasks)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mfor\u001b[39;00m submodel \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mls_model:\n\u001b[0;32m    234\u001b[0m     submodel\u001b[39m.\u001b[39mtasks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     submodel\u001b[39m.\u001b[39;49mlast_pop\u001b[39m.\u001b[39mls_tasks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[39mfor\u001b[39;00m subpop \u001b[39min\u001b[39;00m submodel\u001b[39m.\u001b[39mlast_pop:\n\u001b[0;32m    237\u001b[0m         subpop\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'model' object has no attribute 'last_pop'"
     ]
    }
   ],
   "source": [
    "model = MultiBenchmark(\n",
    "    ls_benchmark= ls_benchmark,\n",
    "    name_benchmark= name_benchmark,\n",
    "    ls_IndClass= ls_IndClass,\n",
    "    model = Model_Test\n",
    ")\n",
    "model.compile(\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation = Polynomial_Mutation(nm = 5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    ")\n",
    "model.fit(\n",
    "    nb_inds_each_task=100,\n",
    "    nb_inds_min=30,\n",
    "    nb_generations=1000,\n",
    "    LSA = True,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "a = model.run(\n",
    "    nb_run= 1,\n",
    "    save_path= \"./model_saved/__static__/WCCI22_complex/model_official/model_benchmark_id_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_result['history_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the result complex benchmark to text file\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_res(res, path_out):\n",
    "#     with open(path_out, 'w') as fi:\n",
    "#         for i in res:\n",
    "#             fi.write(str(int(i[0])) + \", \")\n",
    "#             for j in range(1, len(i)-1):\n",
    "#                 fi.write(str(i[j])+\", \")\n",
    "#             fi.write(str(i[len(i)-1])+\"\\n\")\n",
    "\n",
    "# len_out_complex = 100\n",
    "\n",
    "# for id in range(1, 11):\n",
    "\n",
    "#     model_mbm = loadModel(f\"model_saved\\__static__\\WCCI22_complex\\model_official\\model_benchmark_id_{id}.mso\", ls_tasks=WCCI22_benchmark.get_complex_benchmark(id))\n",
    "\n",
    "#     res = model_mbm.ls_model[0].history_cost[:len_out_complex]\n",
    "#     for i in range(1,model_mbm.nb_run):\n",
    "#         res = np.concatenate((res, np.array(model_mbm.ls_model[i].history_cost[:100])), 1)\n",
    "#     res.shape[0]\n",
    "#     num_evals = (np.arange(1, res.shape[0] + 1) * 1000 * len(model_mbm.tasks)).reshape(-1,1)\n",
    "#     out = np.concatenate((num_evals, res), 1)\n",
    "\n",
    "\n",
    "\n",
    "#     write_res(out, f\"./result/MTO-complex/MTOSOO_P{id}.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b755264e74d2c54d302155e7ba1426216751b8619e27e7d20d668d5785a6140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
