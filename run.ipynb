{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFEA_lib.model import Model_Offical\n",
    "from MFEA_lib.model.utils import *\n",
    "from MFEA_lib.operators.Crossover import *\n",
    "from MFEA_lib.operators.Mutation import *\n",
    "from MFEA_lib.operators.Selection import *\n",
    "from MFEA_lib.operators.Search import *\n",
    "from MFEA_lib.tasks.Benchmark.Funcs import WCCI22_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualDE(Individual):\n",
    "    def __init__(self, genes, dim= None) -> None:\n",
    "        super().__init__(genes, dim)\n",
    "        if genes is None:\n",
    "            self.genes: np.ndarray = np.random.rand(dim)\n",
    "        self.transfer =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_benchmark = []\n",
    "ls_IndClass = []\n",
    "for i in range(1, 11, 1):\n",
    "    t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "    ls_benchmark.append(t)\n",
    "    ls_IndClass.append(IndividualDE)\n",
    "\n",
    "name_benchmark = np.arange(len(ls_benchmark)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 00m 50.13s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 6.01E+02  6.01E+02  ,  hecking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 50.72s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 7.00E+02  7.00E+02  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 45.32s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 5.26E+03  4.93E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 28.02s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 1.30E+03  1.30E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Checking....\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vincent\\Documents\\Lab\\Competition\\official\\MFEA_MSO\\MFEA_lib\\model\\utils.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.array(result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 00m 40.43s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 1.52E+03  1.52E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 53.83s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 5.69E+03  6.94E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 50.63s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 2.77E+03  2.63E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 37.87s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 5.21E+02  5.21E+02  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 34.24s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 8.49E+03  1.62E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n",
      "Time: 00m 45.49s  100 % [====================>]  Pop_size: 1.86E+02  ,  Cost: 2.25E+03  6.99E+03  ,  Checking...Checking...DONE!\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "model = MultiBenchmark(\n",
    "    ls_benchmark= ls_benchmark,\n",
    "    name_benchmark= name_benchmark,\n",
    "    ls_IndClass= ls_IndClass,\n",
    "    model = Model_Offical\n",
    ")\n",
    "model.compile(\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation = Polynomial_Mutation(nm = 5),\n",
    "    selection= ElitismSelection(random_percent= 0.),\n",
    ")\n",
    "model.fit(\n",
    "    nb_inds_each_task=100,\n",
    "    nb_inds_min=30,\n",
    "    nb_generations=1000,\n",
    "    LSA = True,\n",
    "    evaluate_initial_skillFactor= True\n",
    ")\n",
    "a = model.run(\n",
    "    nb_run= 3,\n",
    "    save_path= \"./model_saved/__static__/WCCI22_complex/model_official/model_benchmark_id_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the result complex benchmark to text file\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_res(res, path_out):\n",
    "    with open(path_out, 'w') as fi:\n",
    "        for i in res:\n",
    "            fi.write(str(int(i[0])) + \", \")\n",
    "            for j in range(1, len(i)-1):\n",
    "                fi.write(str(i[j])+\", \")\n",
    "            fi.write(str(i[len(i)-1])+\"\\n\")\n",
    "\n",
    "len_out_complex = 100\n",
    "\n",
    "for id in range(1, 11):\n",
    "\n",
    "    model_mbm = loadModel(f\"model_saved\\__static__\\WCCI22_complex\\model_official\\model_benchmark_id_{id}.mso\", ls_tasks=WCCI22_benchmark.get_complex_benchmark(id))\n",
    "\n",
    "    res = model_mbm.ls_model[0].history_cost[:len_out_complex]\n",
    "    for i in range(1,model_mbm.nb_run):\n",
    "        res = np.concatenate((res, np.array(model_mbm.ls_model[i].history_cost[:100])), 1)\n",
    "    res.shape[0]\n",
    "    num_evals = (np.arange(1, res.shape[0] + 1) * 1000 * len(model_mbm.tasks)).reshape(-1,1)\n",
    "    out = np.concatenate((num_evals, res), 1)\n",
    "\n",
    "\n",
    "\n",
    "    write_res(out, f\"./result/MTO-complex/MTOSOO_P{id}.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('learnCS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2d74ce3e99bc2d991502eaa9ff6878b69f13ebfe616751bd67e96721470575f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
